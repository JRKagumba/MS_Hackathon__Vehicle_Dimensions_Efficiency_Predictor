{"cells":[{"cell_type":"markdown","source":["# **02.1 Data Cleaning - Vehicle Dimension Data**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"95cb1d71-43cf-45b5-8c72-926809336091"},{"cell_type":"code","source":["!pip install simpledbf"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":3,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8256685Z","session_start_time":"2024-02-29T00:31:09.3991409Z","execution_start_time":"2024-02-29T00:31:50.325483Z","execution_finish_time":"2024-02-29T00:32:05.2473681Z","parent_msg_id":"f8342e39-ef2b-4f54-9fd0-72ac9ec5739d"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 3, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting simpledbf\n  Downloading simpledbf-0.2.6.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25hBuilding wheels for collected packages: simpledbf\n  Building wheel for simpledbf (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n\u001b[?25h  Created wheel for simpledbf: filename=simpledbf-0.2.6-py3-none-any.whl size=13784 sha256=322a1a12bf478d8b85e951fdc8f17aa3c5b9369595065ecf9cb73ef85297d4a9\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/e5/41/13/ebdef29165b9309ec4e235dbff19eca8b6759125b0924ad430\nSuccessfully built simpledbf\nInstalling collected packages: simpledbf\nSuccessfully installed simpledbf-0.2.6\n"]}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7fb639ca-633b-4061-bf21-b1cb30703b04"},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import re\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from simpledbf import Dbf5 #to convert .dbf files to .csv"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":4,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8313136Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:05.7741284Z","execution_finish_time":"2024-02-29T00:32:18.0261362Z","parent_msg_id":"e3333b75-c043-4855-adf2-4904626eb45b"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 4, Finished, Available)"},"metadata":{}}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"90274c2a-6651-4616-90f2-f2a427f51a91"},{"cell_type":"markdown","source":["## Overview\n","The following cell automates the preparation of raw data files for intermediate processing. It involves organizing and converting files from a source directory to a designated target directory, focusing on `.dbf` and `.csv` file formats.\n","\n","## Steps\n","1. **Directories Setup**: Identifies source (`/lakehouse/default/Files/data/raw`) and target (`/lakehouse/default/Files/data/intermediate`) directories for file processing.\n","2. **Target Directory Creation**: Checks for the target directory's existence; if absent, it's created.\n","3. **File Filtering**: Lists all `.dbf` and `.csv` files in the source directory for processing.\n","4. **File Processing**:\n","   - For `.dbf` files, converts them to `.csv` format using `Dbf5` and saves them in the target directory with standardized lowercase names.\n","   - Directly copies `.csv` files to the target directory after standardizing the file names to lowercase.\n","\n","This script ensures all relevant data files are standardized and located in a single directory, ready for further data analysis or processing tasks.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"bb02edf1-da9c-489f-aa21-aa1a9b7e8a71"},{"cell_type":"code","source":["# Define source and target directories\n","source_dir = '/lakehouse/default/Files/data/raw'\n","target_dir = '/lakehouse/default/Files/data/intermediate'\n","\n","# Create the target directory if it doesn't exist\n","if not os.path.exists(target_dir):\n","    os.makedirs(target_dir)\n","\n","# List all files in the source directory\n","files = [file for file in os.listdir(source_dir) if file.lower().endswith('.dbf') or file.lower().endswith('.csv')]\n","\n","for file in files:\n","    # Set the full path for source and target files\n","    source_file_path = os.path.join(source_dir, file)\n","    \n","    # Standardize the file name to lowercase \"spe\" format\n","    standardized_file_name = file.lower().replace('SPE', 'spe')\n","    target_file_path = os.path.join(target_dir, os.path.splitext(standardized_file_name)[0] + '.csv')\n","    \n","    # Check if the file is a DBF file\n","    if file.lower().endswith('.dbf'):\n","        # Convert DBF to CSV\n","        dbf = Dbf5(source_file_path)\n","        df = dbf.to_dataframe()\n","        \n","        # Save to CSV in the target directory\n","        df.to_csv(target_file_path, index=False)\n","        print(f\"Converted {file} to CSV and saved to {target_file_path}\")\n","    elif file.lower().endswith('.csv'):\n","        # If the file is already a CSV, simply copy it to the target directory\n","        # This assumes you want to unify the location/format and not necessarily only convert formats\n","        import shutil\n","        shutil.copy(source_file_path, target_file_path)\n","        print(f\"Copied {file} to {target_file_path}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":5,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8319379Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:18.5364823Z","execution_finish_time":"2024-02-29T00:32:29.0059589Z","parent_msg_id":"f74f7817-ba5f-4bf3-b993-3d2966e9951e"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 5, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["PyTables is not installed. No support for HDF output.\nConverted SPE2010.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2010.csv\nConverted SPE2011.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2011.csv\nConverted spe1971.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1971.csv\nConverted spe1972.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1972.csv\nConverted spe1973.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1973.csv\nConverted spe1974.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1974.csv\nConverted spe1975.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1975.csv\nConverted spe1976.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1976.csv\nConverted spe1977.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1977.csv\nConverted spe1978.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1978.csv\nConverted spe1979.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1979.csv\nConverted spe1980.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1980.csv\nConverted spe1981.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1981.csv\nConverted spe1982.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1982.csv\nConverted spe1983.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1983.csv\nConverted spe1984.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1984.csv\nConverted spe1985.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1985.csv\nConverted spe1986.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1986.csv\nConverted spe1987.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1987.csv\nConverted spe1988.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1988.csv\nConverted spe1989.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1989.csv\nConverted spe1990.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1990.csv\nConverted spe1991.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1991.csv\nConverted spe1992.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1992.csv\nConverted spe1993.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1993.csv\nConverted spe1994.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1994.csv\nConverted spe1995.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1995.csv\nConverted spe1996.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1996.csv\nConverted spe1997.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1997.csv\nConverted spe1998.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1998.csv\nConverted spe1999.DBF to CSV and saved to /lakehouse/default/Files/data/intermediate/spe1999.csv\nConverted spe2000.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2000.csv\nConverted spe2001.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2001.csv\nConverted spe2002.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2002.csv\nConverted spe2003.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2003.csv\nConverted spe2004.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2004.csv\nConverted spe2005.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2005.csv\nConverted spe2006.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2006.csv\nConverted spe2007.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2007.csv\nCopied spe2008.csv to /lakehouse/default/Files/data/intermediate/spe2008.csv\nConverted spe2009.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2009.csv\nCopied spe2011.csv to /lakehouse/default/Files/data/intermediate/spe2011.csv\nConverted spe2012.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2012.csv\nConverted spe2013.dbf to CSV and saved to /lakehouse/default/Files/data/intermediate/spe2013.csv\nCopied spe2014.csv to /lakehouse/default/Files/data/intermediate/spe2014.csv\nCopied spe2015.csv to /lakehouse/default/Files/data/intermediate/spe2015.csv\nCopied spe2016.csv to /lakehouse/default/Files/data/intermediate/spe2016.csv\nCopied spe2017.csv to /lakehouse/default/Files/data/intermediate/spe2017.csv\nCopied spe2018.csv to /lakehouse/default/Files/data/intermediate/spe2018.csv\nCopied spe2019.csv to /lakehouse/default/Files/data/intermediate/spe2019.csv\nCopied spe2020.csv to /lakehouse/default/Files/data/intermediate/spe2020.csv\nCopied spe2021.csv to /lakehouse/default/Files/data/intermediate/spe2021.csv\nCopied spe2022.csv to /lakehouse/default/Files/data/intermediate/spe2022.csv\nCopied spe2023.csv to /lakehouse/default/Files/data/intermediate/spe2023.csv\nCopied spe2024.csv to /lakehouse/default/Files/data/intermediate/spe2024.csv\nCopied vehicles_mpg.csv to /lakehouse/default/Files/data/intermediate/vehicles_mpg.csv\n"]}],"execution_count":3,"metadata":{},"id":"60bdefa3-70ba-4138-a9ae-1a1d2f4ad0d5"},{"cell_type":"markdown","source":["## Overview\n","The cell below, identifies and processes vehicle specification files from a specific directory, updating counts for each column present across files.\n","\n","## Key Components\n","- **Target Directory**: Sets the directory where the files are located.\n","- **Column Counts Initialization**: Initializes a dictionary to track the occurrence of each column.\n","- **File Pattern Matching**: Uses a regular expression to identify files following a specific naming convention.\n","- **Column Descriptions Mapping**: Provides human-readable descriptions for each column present in the files.\n","- **File Processing**: Lists all files in the target directory matching the pattern, reads them, and updates the column counts.\n","- **Total Files Calculation**: Computes the total number of files processed.\n","- **Information Display**: Outputs the count and description of each column found across all files.\n","\n","## Data Dictionary\n","\n","- `MAKE`: Vehicle Make\n","- `MODEL`: Vehicle Model\n","- `MYR`: Last two digits of the year data was compiled\n","- `A`: Longitudinal distance front bumper to windshield base\n","- `B`: Distance rear bumper to backlight base (varies by vehicle type)\n","- `C`: Maximum vertical height of the side glass\n","- `D`: Vertical distance base of side glass to lower edge of rocker panel\n","- `E`: Distance between side rails or maximum width of top\n","- `F`: Front overhang\n","- `G`: Rear overhang\n","- `OL`: Overall length\n","- `OW`: Overall width\n","- `OH`: Overall height\n","- `WB`: Wheelbase\n","- `TWF`: Front track width\n","- `TWR`: Rear track width\n","- `CW`: Curb weight\n","- `WDIST`: Weight distribution (Front/Rear)\n","\n","Source: [Open Data Canada - Vehicle Specifications Dataset](https://open.canada.ca/data/dataset/913f8940-036a-45f2-a5f2-19bde76c1252)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"11a2dccf-7de7-48c9-98ec-87805492f716"},{"cell_type":"code","source":["# Define the target directory\n","target_dir = '/lakehouse/default/Files/data/intermediate'\n","\n","# Initialize a dictionary to hold column names and their counts\n","column_counts = {}\n","\n","# Regular expression to match files named \"speYEAR.csv\"\n","file_pattern = re.compile(r'spe\\d{4}\\.csv$', re.IGNORECASE)\n","\n","# Mapping of column names to descriptions\n","column_descriptions = {\n","    'MAKE': 'Vehicle Make',\n","    'MODEL': 'Vehicle Model',\n","    'MYR': 'Last two digits of the year data was compiled',\n","    'A1': 'Longitudinal distance front bumper to windshield base',\n","    'B1': 'Distance rear bumper to backlight base (varies by vehicle type)',\n","    'C1': 'Maximum vertical height of the side glass',\n","    'D1': 'Vertical distance base of side glass to lower edge of rocker panel',\n","    'E1': 'Distance between side rails or maximum width of top',\n","    'F1': 'Front overhang',\n","    'G1': 'Rear overhang',\n","    'OL': 'Overall length',\n","    'OW': 'Overall width',\n","    'OH': 'Overall height',\n","    'WB': 'Wheelbase',\n","    'TWF': 'Front track width',\n","    'TWR': 'Rear track width',\n","    'CW': 'Curb weight',\n","    'WDIST': 'Weight distribution (Front/Rear)',\n","}\n","\n","# List and process files\n","for file_ in os.listdir(target_dir):\n","    if file_pattern.match(file_):\n","        file_path = os.path.join(target_dir, file_)\n","        try:\n","            # Read the file_ into a DataFrame\n","            df = pd.read_csv(file_path)\n","            \n","            # Update counts for each column in this file_\n","            for column in df.columns:\n","                column_counts[column] = column_counts.get(column, 0) + 1\n","        except Exception as e:\n","            print(f\"Error processing file {file_}: {e}\")\n","\n","# Calculate total number of files processed\n","total_files = sum(1 for file_ in os.listdir(target_dir) if file_pattern.match(file_))\n","\n","# Display the information\n","for column, count in column_counts.items():\n","    description = column_descriptions.get(column, \"Unknown description\")\n","    print(f\"{column}: {count}/{total_files} - {description}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":6,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8325401Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:29.5079086Z","execution_finish_time":"2024-02-29T00:32:30.3797618Z","parent_msg_id":"d2fdcf67-1656-45af-aba3-e61efa8a7aad"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 6, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["MAKE: 56/56 - Vehicle Make\nMODEL: 56/56 - Vehicle Model\nMYR: 36/56 - Last two digits of the year data was compiled\nOL: 56/56 - Overall length\nOW: 56/56 - Overall width\nOH: 56/56 - Overall height\nWB: 56/56 - Wheelbase\nCW: 56/56 - Curb weight\nA1: 56/56 - Longitudinal distance front bumper to windshield base\nB1: 56/56 - Distance rear bumper to backlight base (varies by vehicle type)\nC1: 56/56 - Maximum vertical height of the side glass\nD1: 56/56 - Vertical distance base of side glass to lower edge of rocker panel\nE1: 56/56 - Distance between side rails or maximum width of top\nF1: 56/56 - Front overhang\nG1: 56/56 - Rear overhang\nTWF: 36/56 - Front track width\nTWR: 36/56 - Rear track width\nWDIST: 43/56 - Weight distribution (Front/Rear)\nH1: 16/56 - Unknown description\nI1: 17/56 - Unknown description\nJ1: 18/56 - Unknown description\nK1: 18/56 - Unknown description\nCTC: 2/56 - Unknown description\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6c6d483f-a477-48cb-bf58-4129cc0a79b8"},{"cell_type":"markdown","source":["\n","## Overview\n","The cell below designed to combine data from multiple CSV files into a single DataFrame, ensuring that only files containing specific required columns are included. It supports both Pandas and Dask DataFrames for scalability.\n","\n","- Defines a set of columns that must be present in each CSV file for it to be included in the final combined DataFrame.\n","- Initializes an empty DataFrame. The example shows how to initialize both a regular Pandas DataFrame and a Dask DataFrame for handling larger datasets.\n","- Iterates over files in a specified directory, checking each file for the required columns. If a file meets the criteria, it extracts the year from the file name, adds this as a new column, and appends the data to the combined DataFrame. Errors during file processing are caught and reported."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"15db2274-6109-4dc0-9ddc-794a2896c3cd"},{"cell_type":"code","source":["# Define the required columns \n","required_columns = set([\n","    'MAKE', 'MODEL', 'MYR', 'A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G1', \n","    'OL', 'OW', 'OH', 'WB', 'TWF', 'TWR', 'CW', 'WDIST'\n","])\n","\n","# Initialize an empty DataFrame or Dask DataFrame for large data\n","# For a regular pandas DataFrame:\n","combined_df = pd.DataFrame()\n","# For a Dask DataFrame:\n","# combined_df = dd.from_pandas(pd.DataFrame(), npartitions=1)\n","\n","# Iterate over files in the directory again to filter and combine them\n","for file_ in os.listdir(target_dir):\n","    if file_pattern.match(file_):\n","        file_path = os.path.join(target_dir, file_)\n","        try:\n","            # Temporarily read the file to check if it contains the required columns\n","            temp_df = pd.read_csv(file_path)\n","            if required_columns.issubset(temp_df.columns):\n","                # Extract year from file name\n","                file_year = re.search(r'spe(\\d{4})\\.csv', file_).group(1)\n","                # Add FILE_YEAR column\n","                temp_df['FILE_YEAR'] = file_year\n","                # Append to the combined DataFrame\n","                if isinstance(combined_df, pd.DataFrame):\n","                    combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n","                else:\n","                    combined_df = dd.concat([combined_df, dd.from_pandas(temp_df, npartitions=1)], ignore_index=True)\n","        except Exception as e:\n","            print(f\"Error processing file {file_}: {e}\")\n","\n","# If using Dask, you can compute the final result or save it directly without computing\n","# For example, to save to a Parquet file (good for large datasets)\n","# combined_df.to_parquet('/path/to/save/your_large_dataset.parquet')\n","\n","# If the data is manageable in memory and you're using pandas\n","combined_df.to_csv('/lakehouse/default/Files/data/intermediate/yearly_combined_dimension_data.csv', index=False)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":7,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8386266Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:30.9799742Z","execution_finish_time":"2024-02-29T00:32:32.6070034Z","parent_msg_id":"d34cc3e7-8d76-416d-b58b-1852113e65ab"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 7, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Error processing file SPE2010.csv: 'NoneType' object has no attribute 'group'\nError processing file SPE2011.csv: 'NoneType' object has no attribute 'group'\n"]}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"bf082329-c974-4d21-84fd-f9af552405b0"},{"cell_type":"code","source":["combined_df.tail()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8391901Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:33.1216851Z","execution_finish_time":"2024-02-29T00:32:33.3981091Z","parent_msg_id":"75350730-fb7e-4fe0-9901-58e9179b4d0c"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 8, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"        MAKE                     MODEL   MYR     OL     OW     OH   WB  \\\n24940  VOLVO       850 4DR WAGON TURBO  94.0  471.0  176.0  142.0  267   \n24941  VOLVO  940 4DR SEDAN BASE/TURBO  91.0  487.0  176.0  141.0  277   \n24942  VOLVO  940 4DR WAGON BASE/TURBO  91.0  481.0  176.0  143.0  277   \n24943  VOLVO             960 4DR SEDAN  92.0  487.0  175.0  141.0  277   \n24944  VOLVO             960 4DR WAGON  92.0  481.0  176.0  143.0  277   \n\n           CW     A1     B1    C1    D1     E1    F1     G1    TWF    TWR  \\\n24940  1542.0  130.0  214.0  41.0  69.0  130.0  98.0  108.0  152.0  147.0   \n24941  1455.0  149.0   69.0  41.0  67.0  129.0  99.0  110.0  147.0  146.0   \n24942  1489.0  149.0  228.0  41.0  67.0  129.0  99.0  107.0  147.0  146.0   \n24943  1591.0  149.0   69.0  41.0  67.0  129.0  99.0  110.0  147.0  152.0   \n24944  1565.0  149.0  228.0  41.0  67.0  129.0  99.0  107.0  147.0  146.0   \n\n       WDIST FILE_YEAR  \n24940    NaN      1994  \n24941  53/47      1994  \n24942    NaN      1994  \n24943  53/47      1994  \n24944    NaN      1994  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAKE</th>\n      <th>MODEL</th>\n      <th>MYR</th>\n      <th>OL</th>\n      <th>OW</th>\n      <th>OH</th>\n      <th>WB</th>\n      <th>CW</th>\n      <th>A1</th>\n      <th>B1</th>\n      <th>C1</th>\n      <th>D1</th>\n      <th>E1</th>\n      <th>F1</th>\n      <th>G1</th>\n      <th>TWF</th>\n      <th>TWR</th>\n      <th>WDIST</th>\n      <th>FILE_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24940</th>\n      <td>VOLVO</td>\n      <td>850 4DR WAGON TURBO</td>\n      <td>94.0</td>\n      <td>471.0</td>\n      <td>176.0</td>\n      <td>142.0</td>\n      <td>267</td>\n      <td>1542.0</td>\n      <td>130.0</td>\n      <td>214.0</td>\n      <td>41.0</td>\n      <td>69.0</td>\n      <td>130.0</td>\n      <td>98.0</td>\n      <td>108.0</td>\n      <td>152.0</td>\n      <td>147.0</td>\n      <td>NaN</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>24941</th>\n      <td>VOLVO</td>\n      <td>940 4DR SEDAN BASE/TURBO</td>\n      <td>91.0</td>\n      <td>487.0</td>\n      <td>176.0</td>\n      <td>141.0</td>\n      <td>277</td>\n      <td>1455.0</td>\n      <td>149.0</td>\n      <td>69.0</td>\n      <td>41.0</td>\n      <td>67.0</td>\n      <td>129.0</td>\n      <td>99.0</td>\n      <td>110.0</td>\n      <td>147.0</td>\n      <td>146.0</td>\n      <td>53/47</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>24942</th>\n      <td>VOLVO</td>\n      <td>940 4DR WAGON BASE/TURBO</td>\n      <td>91.0</td>\n      <td>481.0</td>\n      <td>176.0</td>\n      <td>143.0</td>\n      <td>277</td>\n      <td>1489.0</td>\n      <td>149.0</td>\n      <td>228.0</td>\n      <td>41.0</td>\n      <td>67.0</td>\n      <td>129.0</td>\n      <td>99.0</td>\n      <td>107.0</td>\n      <td>147.0</td>\n      <td>146.0</td>\n      <td>NaN</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>24943</th>\n      <td>VOLVO</td>\n      <td>960 4DR SEDAN</td>\n      <td>92.0</td>\n      <td>487.0</td>\n      <td>175.0</td>\n      <td>141.0</td>\n      <td>277</td>\n      <td>1591.0</td>\n      <td>149.0</td>\n      <td>69.0</td>\n      <td>41.0</td>\n      <td>67.0</td>\n      <td>129.0</td>\n      <td>99.0</td>\n      <td>110.0</td>\n      <td>147.0</td>\n      <td>152.0</td>\n      <td>53/47</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>24944</th>\n      <td>VOLVO</td>\n      <td>960 4DR WAGON</td>\n      <td>92.0</td>\n      <td>481.0</td>\n      <td>176.0</td>\n      <td>143.0</td>\n      <td>277</td>\n      <td>1565.0</td>\n      <td>149.0</td>\n      <td>228.0</td>\n      <td>41.0</td>\n      <td>67.0</td>\n      <td>129.0</td>\n      <td>99.0</td>\n      <td>107.0</td>\n      <td>147.0</td>\n      <td>146.0</td>\n      <td>NaN</td>\n      <td>1994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9c13d681-d929-4f73-91dc-4f8877099267"},{"cell_type":"code","source":["# Calculate the number of null values per column\n","null_counts = combined_df.isnull().sum()\n","\n","# Calculate the total number of entries in the DataFrame\n","total_entries = len(combined_df)\n","\n","# Calculate the percentage of null values per column\n","null_percentage = (null_counts / total_entries) * 100\n","\n","# Create a report as a DataFrame for better readability\n","null_report = pd.DataFrame({\n","    'Column': null_counts.index,\n","    'Null Values': null_counts.values,\n","    'Percentage (%)': null_percentage.values\n","}).sort_values(by='Percentage (%)', ascending=False)\n","\n","# Display the report\n","print(null_report)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":9,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8397287Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:33.9318083Z","execution_finish_time":"2024-02-29T00:32:34.245919Z","parent_msg_id":"58ad218c-7838-4e7a-baa2-1ca856dbe416"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 9, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["       Column  Null Values  Percentage (%)\n17      WDIST         7078       28.374424\n12         E1         1448        5.804770\n10         C1         1324        5.307677\n9          B1         1287        5.159351\n16        TWR         1089        4.365604\n11         D1         1017        4.076969\n8          A1         1015        4.068952\n14         G1          976        3.912608\n13         F1          969        3.884546\n15        TWF          884        3.543796\n7          CW          503        2.016436\n5          OH          484        1.940269\n2         MYR          106        0.424935\n4          OW           83        0.332732\n6          WB           13        0.052115\n3          OL            9        0.036079\n0        MAKE            0        0.000000\n1       MODEL            0        0.000000\n18  FILE_YEAR            0        0.000000\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"b3617baa-ecab-4ef0-a0e2-37358a069852"},{"cell_type":"code","source":["# Remove all rows that contain at least one null value\n","cleaned_df = combined_df.dropna()\n","\n","# If you want to ensure changes are made to the original DataFrame, you can also use inplace=True\n","# combined_df.dropna(inplace=True)\n","\n","# Optional: If you're curious about how many rows were dropped\n","rows_before = len(combined_df)\n","rows_after = len(cleaned_df)\n","rows_dropped = rows_before - rows_after\n","\n","print(f\"Rows before cleaning: {rows_before}\")\n","print(f\"Rows after cleaning: {rows_after}\")\n","print(f\"Total rows dropped: {rows_dropped}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.840267Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:34.7296527Z","execution_finish_time":"2024-02-29T00:32:35.0260236Z","parent_msg_id":"232c2a56-7afb-4380-8ad0-dcacae64cbf4"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 10, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Rows before cleaning: 24945\nRows after cleaning: 16661\nTotal rows dropped: 8284\n"]}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"06ee3c9e-62ef-45c9-86c0-dc4fa70c9f1c"},{"cell_type":"markdown","source":["## Overview\n","The code cell below is used to convert a Model Year Representation (MYR) to a full year format in a DataFrame, utilizing the file year as a proxy for the actual vehicle year.\n","\n","## Strategy\n","- **Extract MYR:** Split the MYR at the decimal point, use the first part.\n","- **Year Prefix:** Prefix the MYR with the first two digits of `FILE_YEAR` to form a full year.\n","- **Adjustment Logic:** If the resultant year is off by more than 10 years from `FILE_YEAR`, adjust by adding or subtracting 100.\n","\n","## Implementation Notes\n","- Ensures MYR prefix has two digits, adding a '0' if necessary.\n","- The strategy relies on `FILE_YEAR` to approximate the century, adjusting for anomalies.\n","- Applied to a DataFrame, updating the MYR to a full year and ensuring it is in integer format.\n","\n","This method cleverly uses the file year to deduce the correct century for the vehicle model year, adjusting for potential errors in MYR.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e523d5fb-df0c-4bed-a281-2f404666314e"},{"cell_type":"code","source":["# Function to convert MYR to a full year format\n","def convert_myr_to_full_year(row):\n","    # Attempt to extract the year component from MYR correctly, considering it's in floating point format\n","    myr_str = str(row['MYR'])\n","    myr_prefix = myr_str.split('.')[0]  # Extract the digits before any decimal point\n","\n","    # Ensure the extracted MYR prefix has at least two digits\n","    if len(myr_prefix) == 1:\n","        myr_prefix = '0' + myr_prefix  # Prefix with 0 if only one digit is present\n","\n","    file_year_prefix = str(row['FILE_YEAR'])[:2]  # Extract the century\n","    potential_year = int(file_year_prefix + myr_prefix)  # Combine to form the full year\n","\n","    # Adjust for cases where the difference between FILE_YEAR and potential_year is significant\n","    file_year = int(row['FILE_YEAR'])\n","    if abs(potential_year - file_year) > 10:\n","        if potential_year > file_year:\n","            potential_year -= 100  # Adjust down if MYR indicates a year past FILE_YEAR\n","        else:\n","            potential_year += 100  # Adjust up if MYR indicates a year before FILE_YEAR\n","\n","    return potential_year\n","\n","# Apply the correction and update the DataFrame\n","cleaned_df['Adjusted_MYR'] = cleaned_df.apply(convert_myr_to_full_year, axis=1)\n","\n","# Convert Adjusted_MYR to integer\n","cleaned_df['Adjusted_MYR'] = cleaned_df['Adjusted_MYR'].astype(int)\n","\n","# Verify the changes\n","cleaned_df[['MYR', 'FILE_YEAR', 'Adjusted_MYR']].tail()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":11,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8444356Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:35.5362137Z","execution_finish_time":"2024-02-29T00:32:36.406012Z","parent_msg_id":"0083d45d-6dc6-4dff-b6fc-7e0ca0d773f5"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 11, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/tmp/ipykernel_5824/3661407067.py:25: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  cleaned_df['Adjusted_MYR'] = cleaned_df.apply(convert_myr_to_full_year, axis=1)\n/tmp/ipykernel_5824/3661407067.py:28: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  cleaned_df['Adjusted_MYR'] = cleaned_df['Adjusted_MYR'].astype(int)\n"]},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"        MYR FILE_YEAR  Adjusted_MYR\n24934  92.0      1994          1992\n24937  93.0      1994          1993\n24938  93.0      1994          1993\n24941  91.0      1994          1991\n24943  92.0      1994          1992","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MYR</th>\n      <th>FILE_YEAR</th>\n      <th>Adjusted_MYR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24934</th>\n      <td>92.0</td>\n      <td>1994</td>\n      <td>1992</td>\n    </tr>\n    <tr>\n      <th>24937</th>\n      <td>93.0</td>\n      <td>1994</td>\n      <td>1993</td>\n    </tr>\n    <tr>\n      <th>24938</th>\n      <td>93.0</td>\n      <td>1994</td>\n      <td>1993</td>\n    </tr>\n    <tr>\n      <th>24941</th>\n      <td>91.0</td>\n      <td>1994</td>\n      <td>1991</td>\n    </tr>\n    <tr>\n      <th>24943</th>\n      <td>92.0</td>\n      <td>1994</td>\n      <td>1992</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"73473ff4-daa1-4369-b4f8-c3cbe2b5ba03"},{"cell_type":"code","source":["cleaned_df.head()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":12,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:31:08.8450372Z","session_start_time":null,"execution_start_time":"2024-02-29T00:32:36.9005319Z","execution_finish_time":"2024-02-29T00:32:37.2106525Z","parent_msg_id":"aa95ce21-13b6-43c2-9882-7467f97b181b"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 12, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"    MAKE                                          MODEL   MYR     OL     OW  \\\n0  ACURA                           ILX 4DR SEDAN/HYBRID  12.0  454.0  180.0   \n1  ACURA                     MDX 4DR SUV AWD/TECH/ELITE  10.0  485.0  199.0   \n3  ACURA                         TL 4 DR SEDAN FWD/TECH  12.0  493.0  188.0   \n4  ACURA  TL 4 DR SEDAN SH-AWD/SH-AWD TECH/SH-AWD ELITE  12.0  493.0  188.0   \n5  ACURA         TSX 4DR SEDAN FWD TECH PACKAGE/PREMIUM   9.0  473.0  184.0   \n\n      OH   WB      CW     A1     B1    C1    D1     E1     F1     G1    TWF  \\\n0  141.0  267  1356.0  121.0   51.0  30.0  79.0  114.0   96.0   91.0  150.0   \n1  173.0  275  2076.0  117.0  183.0  42.0  85.0  126.0  100.0  110.0  172.0   \n3  145.0  278  1695.0  140.0   65.0  32.0  81.0  115.0  102.0  113.0  161.0   \n4  145.0  278  1807.0  140.0   65.0  32.0  81.0  115.0  102.0  113.0  161.0   \n5  144.0  271  1545.0  121.0   44.0  35.0  79.0  115.0   97.0  104.0  158.0   \n\n     TWR  WDIST FILE_YEAR  Adjusted_MYR  \n0  152.0  60/40      2013          2012  \n1  172.0  56/44      2013          2010  \n3  162.0  61/39      2013          2012  \n4  162.0  59/41      2013          2012  \n5  158.0  60/40      2013          2009  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAKE</th>\n      <th>MODEL</th>\n      <th>MYR</th>\n      <th>OL</th>\n      <th>OW</th>\n      <th>OH</th>\n      <th>WB</th>\n      <th>CW</th>\n      <th>A1</th>\n      <th>B1</th>\n      <th>C1</th>\n      <th>D1</th>\n      <th>E1</th>\n      <th>F1</th>\n      <th>G1</th>\n      <th>TWF</th>\n      <th>TWR</th>\n      <th>WDIST</th>\n      <th>FILE_YEAR</th>\n      <th>Adjusted_MYR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ACURA</td>\n      <td>ILX 4DR SEDAN/HYBRID</td>\n      <td>12.0</td>\n      <td>454.0</td>\n      <td>180.0</td>\n      <td>141.0</td>\n      <td>267</td>\n      <td>1356.0</td>\n      <td>121.0</td>\n      <td>51.0</td>\n      <td>30.0</td>\n      <td>79.0</td>\n      <td>114.0</td>\n      <td>96.0</td>\n      <td>91.0</td>\n      <td>150.0</td>\n      <td>152.0</td>\n      <td>60/40</td>\n      <td>2013</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ACURA</td>\n      <td>MDX 4DR SUV AWD/TECH/ELITE</td>\n      <td>10.0</td>\n      <td>485.0</td>\n      <td>199.0</td>\n      <td>173.0</td>\n      <td>275</td>\n      <td>2076.0</td>\n      <td>117.0</td>\n      <td>183.0</td>\n      <td>42.0</td>\n      <td>85.0</td>\n      <td>126.0</td>\n      <td>100.0</td>\n      <td>110.0</td>\n      <td>172.0</td>\n      <td>172.0</td>\n      <td>56/44</td>\n      <td>2013</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ACURA</td>\n      <td>TL 4 DR SEDAN FWD/TECH</td>\n      <td>12.0</td>\n      <td>493.0</td>\n      <td>188.0</td>\n      <td>145.0</td>\n      <td>278</td>\n      <td>1695.0</td>\n      <td>140.0</td>\n      <td>65.0</td>\n      <td>32.0</td>\n      <td>81.0</td>\n      <td>115.0</td>\n      <td>102.0</td>\n      <td>113.0</td>\n      <td>161.0</td>\n      <td>162.0</td>\n      <td>61/39</td>\n      <td>2013</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ACURA</td>\n      <td>TL 4 DR SEDAN SH-AWD/SH-AWD TECH/SH-AWD ELITE</td>\n      <td>12.0</td>\n      <td>493.0</td>\n      <td>188.0</td>\n      <td>145.0</td>\n      <td>278</td>\n      <td>1807.0</td>\n      <td>140.0</td>\n      <td>65.0</td>\n      <td>32.0</td>\n      <td>81.0</td>\n      <td>115.0</td>\n      <td>102.0</td>\n      <td>113.0</td>\n      <td>161.0</td>\n      <td>162.0</td>\n      <td>59/41</td>\n      <td>2013</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ACURA</td>\n      <td>TSX 4DR SEDAN FWD TECH PACKAGE/PREMIUM</td>\n      <td>9.0</td>\n      <td>473.0</td>\n      <td>184.0</td>\n      <td>144.0</td>\n      <td>271</td>\n      <td>1545.0</td>\n      <td>121.0</td>\n      <td>44.0</td>\n      <td>35.0</td>\n      <td>79.0</td>\n      <td>115.0</td>\n      <td>97.0</td>\n      <td>104.0</td>\n      <td>158.0</td>\n      <td>158.0</td>\n      <td>60/40</td>\n      <td>2013</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9d9e8b5c-5d80-492b-beac-c91c621c8697"},{"cell_type":"code","source":["# Define the file path\n","file_path = '/lakehouse/default/Files/data/processed/processed_vehicle_dimension_data.csv'\n","\n","# Check if the directory exists, if not, create it\n","directory = os.path.dirname(file_path)\n","if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","# Save the final DataFrame to a new file\n","cleaned_df.to_csv(file_path, index=False)\n","\n","print(\"DataFrame saved to:\", file_path)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"ae8e51e6-b347-46c3-82ee-f269c3f7afe2","statement_id":14,"state":"finished","livy_statement_state":"available","queued_time":"2024-02-29T00:37:16.2949188Z","session_start_time":null,"execution_start_time":"2024-02-29T00:37:16.7895993Z","execution_finish_time":"2024-02-29T00:37:17.6468135Z","parent_msg_id":"7b084e31-3b3c-4620-99e7-53d2c7e38564"},"text/plain":"StatementMeta(, ae8e51e6-b347-46c3-82ee-f269c3f7afe2, 14, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DataFrame saved to: /lakehouse/default/Files/data/processed/processed_vehicle_dimension_data.csv\n"]}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8e012627-ca70-4377-8a28-cf5f6b5fe689"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"bbf26f16-b945-4180-9a66-f570fa24bc74","default_lakehouse_name":"vehicle__mpg_vs_dimensions__data","default_lakehouse_workspace_id":"16a2f07d-e771-44f5-a1c9-dd4a77650e09"},"environment":{"environmentId":"bef073b3-dc7a-4b86-8cff-d2032f02ba54","workspaceId":"16a2f07d-e771-44f5-a1c9-dd4a77650e09"}}},"nbformat":4,"nbformat_minor":5}